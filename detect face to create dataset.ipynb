{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the raw images crop the image around the face and store it seprately for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the HAAR OpenCV model to detect faces\n",
    "facec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Source where images are downloaded from webscrapping\n",
    "#content='/Users/ashishtomar/Data Science/Capstone Project/CNN - Mask 2/chinese test data/WithMask/'\n",
    "content='/Users/ashishtomar/Downloads/getty images mask/'\n",
    "\n",
    "#path where to write face cropped images\n",
    "path_to_write='/Users/ashishtomar/Data Science/Capstone Project/CNN - Mask 2/data/Test/WithMask/'\n",
    "\n",
    "#Copy all filenames from content directory to a list\n",
    "filenames = os.listdir(content)\n",
    "#print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ashishtomar/Data Science/Capstone Project/CNN - Mask 2/data/Test/WithMask/mask_187.jpg\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "for fn in filenames:\n",
    "    if not fn.startswith('.'):\n",
    "        path=content+fn\n",
    "        #print(path)\n",
    "        \n",
    "        #read the image file from path\n",
    "        image = cv2.imread(path)\n",
    "        \n",
    "        #convert the image to gray scale, as HAAR model works on gray images\n",
    "        gray1 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #detect face in the image\n",
    "        faces = facec.detectMultiScale(gray1, 1.2, 4)#1.3-->2\n",
    "        #print(len(faces))\n",
    "        \n",
    "        #Loop through if images being found\n",
    "        if len(faces)>=0.1:\n",
    "            for f in faces:\n",
    "                \n",
    "                # Get the facial cordinates from the image  \n",
    "                x, y, w, h = [ v for v in f ]\n",
    "                \n",
    "                #Crop the image from the colored image\n",
    "                #add 20 to increase the framesize around face\n",
    "                face_crop = image[y:y+h+20, x:x+w+20]\n",
    "                \n",
    "                #Write the file to directory\n",
    "                #Create the filename along with the path\n",
    "                filename = path_to_write+\"mask_%i.jpg\"%i\n",
    "                \n",
    "                #Resize the image file before writing\n",
    "                lastimg = cv2.resize(face_crop, (512, 512))\n",
    "                \n",
    "                #write the file\n",
    "                cv2.imwrite(filename, lastimg)\n",
    "                i+=1\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask",
   "language": "python",
   "name": "mask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
